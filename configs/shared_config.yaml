shared_config:
  - broker_connection: &broker_connection
      dev_mode: ${SOLACE_DEV_MODE, false}
      broker_url: ${SOLACE_BROKER_URL, ws://localhost:8008}
      broker_username: ${SOLACE_BROKER_USERNAME, default}
      broker_password: ${SOLACE_BROKER_PASSWORD, default}
      broker_vpn: ${SOLACE_BROKER_VPN, default}
      temporary_queue: ${USE_TEMPORARY_QUEUES, true}
      

  - models:
    planning: &planning_model
      # This dictionary structure tells ADK to use the LiteLlm wrapper.
      # 'model' uses the specific model identifier your endpoint expects.
      model: ${LLM_SERVICE_PLANNING_MODEL_NAME} # Use env var for model name
      # 'api_base' tells LiteLLM where to send the request.
      api_base: ${LLM_SERVICE_ENDPOINT} # Use env var for endpoint URL
      # 'api_key' provides authentication.
      api_key: ${LLM_SERVICE_API_KEY} # Use env var for API key
      # Enable parallel tool calls for planning model
      parallel_tool_calls: true 
      # Prompt Caching Strategy
      cache_strategy: "5m" # none, 5m, 1h

      # max_tokens: ${MAX_TOKENS, 16000} # Set a reasonable max token limit for planning
      # temperature: 0.1 # Lower temperature for more deterministic planning
      

    general: &general_model
      # This dictionary structure tells ADK to use the LiteLlm wrapper.
      # 'model' uses the specific model identifier your endpoint expects.
      model: ${LLM_SERVICE_GENERAL_MODEL_NAME} # Use env var for model name
      # 'api_base' tells LiteLLM where to send the request.
      api_base: ${LLM_SERVICE_ENDPOINT} # Use env var for endpoint URL
      # 'api_key' provides authentication.
      api_key: ${LLM_SERVICE_API_KEY} # Use env var for API key
      # Prompt Caching Strategy
      cache_strategy: "5m" # none, 5m, 1h

    image_gen: &image_generation_model
      # This dictionary structure tells ADK to use the LiteLlm wrapper.
      # 'model' uses the specific model identifier your endpoint expects.
      model: ${IMAGE_MODEL_NAME} # Use env var for model name
      # 'api_base' tells LiteLLM where to send the request.
      api_base: ${IMAGE_SERVICE_ENDPOINT} # Use env var for endpoint URL
      # 'api_key' provides authentication.
      api_key: ${IMAGE_SERVICE_API_KEY} # Use env var for API key

    report_gen: &report_generation_model
      # This dictionary structure tells ADK to use the LiteLlm wrapper.
      # 'model' uses the specific model identifier your endpoint expects.
      model: ${LLM_REPORT_MODEL_NAME} # Use env var for model name
      # 'api_base' tells LiteLLM where to send the request.
      api_base: ${LLM_SERVICE_ENDPOINT} # Use env var for endpoint URL
      # 'api_key' provides authentication.
      api_key: ${LLM_SERVICE_API_KEY} # Use env var for API key

    multimodal: &multimodal_model  "gemini-2.5-flash-preview-04-17"

    # OAuth 2.0 Client Credentials authentication example
    oauth_planning: &oauth_planning_model
      # This dictionary structure tells ADK to use the LiteLlm wrapper with OAuth authentication.
      # 'model' uses the specific model identifier your endpoint expects.
      model: ${LLM_SERVICE_OAUTH_PLANNING_MODEL_NAME} # Use env var for model name
      # 'api_base' tells LiteLLM where to send the request.
      api_base: ${LLM_SERVICE_OAUTH_ENDPOINT} # Use env var for endpoint URL

      # OAuth 2.0 Client Credentials configuration
      oauth_token_url: ${LLM_SERVICE_OAUTH_TOKEN_URL} # OAuth token endpoint URL
      oauth_client_id: ${LLM_SERVICE_OAUTH_CLIENT_ID} # OAuth client identifier
      oauth_client_secret: ${LLM_SERVICE_OAUTH_CLIENT_SECRET} # OAuth client secret
      oauth_scope: ${LLM_SERVICE_OAUTH_SCOPE} # Optional: OAuth scope (space-separated)
      # oauth_ca_cert: ${LLM_SERVICE_OAUTH_CA_CERT_PATH} # Optional: Custom CA certificate path
      oauth_token_refresh_buffer_seconds: ${LLM_SERVICE_OAUTH_TOKEN_REFRESH_BUFFER_SECONDS, 300} # Refresh buffer

      # Enable parallel tool calls for planning model
      parallel_tool_calls: true
      # max_tokens: ${MAX_TOKENS, 16000} # Set a reasonable max token limit for planning
      # temperature: 0.1 # Lower temperature for more deterministic planning

    oauth_general: &oauth_general_model
      # This dictionary structure tells ADK to use the LiteLlm wrapper with OAuth authentication.
      # 'model' uses the specific model identifier your endpoint expects.
      model: ${LLM_SERVICE_OAUTH_GENERAL_MODEL_NAME} # Use env var for model name
      # 'api_base' tells LiteLLM where to send the request.
      api_base: ${LLM_SERVICE_OAUTH_ENDPOINT} # Use env var for endpoint URL

      # OAuth 2.0 Client Credentials configuration
      oauth_token_url: ${LLM_SERVICE_OAUTH_TOKEN_URL} # OAuth token endpoint URL
      oauth_client_id: ${LLM_SERVICE_OAUTH_CLIENT_ID} # OAuth client identifier
      oauth_client_secret: ${LLM_SERVICE_OAUTH_CLIENT_SECRET} # OAuth client secret
      oauth_scope: ${LLM_SERVICE_OAUTH_SCOPE} # Optional: OAuth scope (space-separated)
      # oauth_ca_cert: ${LLM_SERVICE_OAUTH_CA_CERT_PATH} # Optional: Custom CA certificate path
      oauth_token_refresh_buffer_seconds: ${LLM_SERVICE_OAUTH_TOKEN_REFRESH_BUFFER_SECONDS, 300} # Refresh buffer

  - services:
    # Default session service configuration
    session_service: &default_session_service
      type: "memory"
      default_behavior: "PERSISTENT"
    
    # Default artifact service configuration
    artifact_service: &default_artifact_service
      type: "filesystem"
      base_path: "/tmp/samv2"
      artifact_scope: namespace
    
    # Default data tools configuration
    data_tools_config: &default_data_tools_config
      sqlite_memory_threshold_mb: 100
      max_result_preview_rows: 50
      max_result_preview_bytes: 4096
